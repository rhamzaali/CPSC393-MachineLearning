{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a53f06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# loading libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "from PIL import Image\n",
    "\n",
    "# import tensorflow and keras packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# import helper functions\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf52abc0",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks take into account the temporal relationships in sequential data. While we can handle sequential data using densely connected feed forward or 1-D convolutional architectures, they don't often work as well as recurrent architectures which are specifically built for sequential data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e47455d",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks use cells which take in an input (such as a word, or a stock price) and generate an output, just like a node in a feed forward neural network. However, unlike a feed forward neural network, recurrent cells also take in the output of the cell at the previous time step. We call this output the hidden state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0513e96c",
   "metadata": {},
   "source": [
    "Even though RNNs only have a single cell, we are feeding values through it over and over, as if it is a deep network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a6131e",
   "metadata": {},
   "source": [
    "Preparing time-series data for an RNN needs more finessing than the dataset used for Feed Forward or Convolutional Neural Networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b1a82",
   "metadata": {},
   "source": [
    "Suppose you have 20 readings in a sequence (suppose it is the temperature per hour). In order to train the RNN to predict the temperature, I need to take the long sequence and break it into bite sized chunks. Suppose we want to train our model on the past 5 temperature readings and predict the current temperature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0832c59",
   "metadata": {},
   "source": [
    "To do so, we will need to break the sequence of 20 readings into smaller sequences, each with 5 readings as input, and 1 reading as the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805a914",
   "metadata": {},
   "source": [
    "#### Sunspots Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b69c72",
   "metadata": {},
   "source": [
    "We will utilize the sunspots data which looks at the average number of sunspots per month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_df = pd.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-sunspots.csv\")\n",
    "print(sun_df.shape)\n",
    "sun_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b9b2e",
   "metadata": {},
   "source": [
    "Our task will be to predict the average number of sunspots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cae70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first extract the readings as an array, we will also record the time step of each reading\n",
    "series = sun_df[\"Sunspots\"].values.astype(np.float32).reshape(-1, 1)\n",
    "time = np.arange(len(series))\n",
    "print(series)\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data to visualize\n",
    "plt.figure(figsize=(25, 6))\n",
    "plt.plot(time, series)\n",
    "plt.title(\"Monthly Average Sunspots\")\n",
    "plt.xlabel(\"Time (months)\")\n",
    "plt.ylabel(\"Number of Sunspots\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d516e",
   "metadata": {},
   "source": [
    "We will normalize the readings to help the network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba8bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "series = scaler.fit_transform(series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3197ec",
   "metadata": {},
   "source": [
    "We then split the data into training and validation set. Note here that there is no shuffling happening - we want the sequence to be maintained. If using an 80/20 for a train/validation split, then the latest 20% of the data will be used for the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fc23fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_time = int(len(series) * 0.8)\n",
    "X_train = series[:split_time]\n",
    "X_valid = series[split_time:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850b0e4",
   "metadata": {},
   "source": [
    "Similar to the Image Generator that keras provides for easily processing image inputs, we will utilize the Time Series Data Generator function to curate our sequential data. Here we can specify the window size (how long the sequence is), what the target at each time step is, and how to slide the window across time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53fd673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input window size - the number of time steps\n",
    "window_size = 30 # we will use 30 readings at a time to predict the reading right after\n",
    "\n",
    "# define the number of samples per batch\n",
    "batch_size = 32 # how many input windows to process before calculating loss\n",
    "\n",
    "# create the training dataset\n",
    "train_ds = keras.utils.timeseries_dataset_from_array(\n",
    "    data = X_train[:-1], # input data (exclude last point to make windows fit the large sequence)\n",
    "    targets = X_train[window_size:], # target = next value after each window\n",
    "    sequence_length = window_size, # how long each input window is\n",
    "    sequence_stride = 1, # shift the window by 1 each time\n",
    "    shuffle = True, # shuffles the order of input windows being processed (not the values within them!)\n",
    "    batch_size = batch_size # number of sequences per batch\n",
    ")\n",
    "\n",
    "# create the validation dataset\n",
    "valid_ds = keras.utils.timeseries_dataset_from_array(\n",
    "    data = X_valid[:-1], \n",
    "    targets = X_valid[window_size:],\n",
    "    sequence_length = window_size,\n",
    "    sequence_stride = 1, \n",
    "    shuffle = False, \n",
    "    batch_size = batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f81fc11",
   "metadata": {},
   "source": [
    "Let's train a simple RNN with one recurring layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72635fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = keras.Sequential([...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d657ccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = simple_model.fit(train_ds, epochs=20, validation_data=valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f1f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = simple_model.predict(valid_ds).flatten().reshape(-1, 1) # note that predictions are scaled!\n",
    "pred_rescaled = scaler.inverse_transform(pred)\n",
    "\n",
    "valid_rescaled = scaler.inverse_transform(X_valid[window_size:]).reshape(-1, 1)\n",
    "\n",
    "# Plot actual vs predicted sunspot values\n",
    "plt.figure(figsize=(25, 6))\n",
    "plt.plot(valid_rescaled, label=\"Actual Sunspots\")\n",
    "plt.plot(pred_rescaled, label=\"RNN Forecast\")\n",
    "plt.title(\"Sunspots Forecast (Normalized)\")\n",
    "plt.xlabel(\"Time (months)\")\n",
    "plt.ylabel(\"Normalized Sunspot Count\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b00dd22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
