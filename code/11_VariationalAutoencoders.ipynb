{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf22d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# loading libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import tensorflow and keras packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb4596",
   "metadata": {},
   "source": [
    "We will use the MNIST data to create a Convolutional Variational Autoencoder, that can represent images of digits into latent distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f7b605",
   "metadata": {},
   "source": [
    "We will first define a custom layer Sampling that will be used to sample a vector from the latent space. Recall that in theory, the encoder learns the mean and std dev vectors for hidden representation. In implementation, we use the log of the variance vector instead of the std dev vector. This avoids negative variance problems and adds stability to gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be43862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class uses mean and log variance vectors + noise to get a sample z\n",
    "# there is only one function in the class that will generate a sample\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e0e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our z vector (latent representation) is going to be 2-dimensional\n",
    "# this helps with visualization\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf411f",
   "metadata": {},
   "source": [
    "Let's define our Encoder. We will take each image as input, apply some Convolution layers, flatten, and then create our mean and log_var vectors that represent our latent space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc481870",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape=(28, 28, 1)) # 28x28x1 image\n",
    "\n",
    "# convolution layers - note no max pooling, instead stride is used to downsample\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "\n",
    "# flatten the network and create a fully connected layer with 16 units\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "\n",
    "# connect the 6-unit layer to mean and log_var vectors separately\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "\n",
    "# z is then sampled from this distribution\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "# defining our encoder with the correct input and output\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fca87",
   "metadata": {},
   "source": [
    "Similarly, our Decoder will take the z vector and use it to reconstruct the input image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2436fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,)) # input to the decoder\n",
    "\n",
    "# use Conv2DTranspose to upsample \n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "\n",
    "# define the decoder with its input and output\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d204493",
   "metadata": {},
   "source": [
    "Because VAEs require a custom loss function: reconstruction loss + KL loss, we will create a VAE class where we explicitly define our loss and training mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc0d3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE class\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\") # we will track 3 loss values\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    # this function defines how training occurs\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data) # get mean and log_var vector from encoder\n",
    "            reconstruction = self.decoder(z) # reconstruct using decoder\n",
    "            reconstruction_loss = tf.reduce_mean( # reconstruction loss is binary cross entropy\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            # KL regularization error\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss # compute total loss\n",
    "\n",
    "        # explicitly calculate gradients    \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights)) # back prop\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1481d7",
   "metadata": {},
   "source": [
    "Now we can train our VAE on MNIST digits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abd36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(mnist_digits, epochs=10, batch_size=128, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c192dab",
   "metadata": {},
   "source": [
    "Now we can sample a random noise vector from Standard Normal Distribution and ask the Decoder to construct the digit image associated with that noise vector in the latent space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8bd633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_dim = 2 in your model\n",
    "random_latent_vector = np.random.normal(size=(1, latent_dim))\n",
    "print(random_latent_vector)\n",
    "\n",
    "generated_digit = decoder.predict(random_latent_vector)\n",
    "\n",
    "plt.imshow(generated_digit[0, :, :, 0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe5ffb2",
   "metadata": {},
   "source": [
    "To get a good sense of the learned latent space, we can sample points in that space and ask the Decoder to generate digit images for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322ee968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function will display a two-dimensional manifold of digits\n",
    "def plot_latent_space(vae, n=30, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    digit_size = 28\n",
    "    scale = 1.0\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = vae.decoder.predict(z_sample, verbose = 0)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216d8e8",
   "metadata": {},
   "source": [
    "We can also perform interpolation between two digits to observe how a continuous smooth translation is formed between them in the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick two random digits from MNIST\n",
    "digit1 = mnist_digits[0:1]  # shape (1,28,28,1)\n",
    "digit2 = mnist_digits[1:2]\n",
    "\n",
    "# encode them to get latent vectors\n",
    "z_mean1, z_log_var1, z1 = encoder.predict(digit1)\n",
    "z_mean2, z_log_var2, z2 = encoder.predict(digit2)\n",
    "\n",
    "\n",
    "num_steps = 10 # intermediate images\n",
    "interpolated_latents = []\n",
    "\n",
    "# interpolate between the two digits\n",
    "for alpha in np.linspace(0, 1, num_steps):\n",
    "    z_interp = (1 - alpha) * z1 + alpha * z2\n",
    "    interpolated_latents.append(z_interp)\n",
    "\n",
    "interpolated_latents = np.concatenate(interpolated_latents, axis=0) # update shape\n",
    "\n",
    "# generate digit images\n",
    "interpolated_digits = decoder.predict(interpolated_latents)\n",
    "\n",
    "# plot them all in a line\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(num_steps):\n",
    "    plt.subplot(1, num_steps, i+1)\n",
    "    plt.imshow(interpolated_digits[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3002abb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
