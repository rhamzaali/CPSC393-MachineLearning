{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53f06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# loading libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "\n",
    "# import tensorflow and keras packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395c0d3",
   "metadata": {},
   "source": [
    "We will load the MNIST data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5efc79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data from keras.datasets\n",
    "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train_mnist = X_train_mnist.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "X_test_mnist = X_test_mnist.reshape(-1, 28*28).astype('float32') / 255.0\n",
    "\n",
    "# Convert y labels to one-hot encoded vectors\n",
    "y_train_mnist = keras.utils.to_categorical(y_train_mnist, num_classes=10)\n",
    "y_test_mnist = keras.utils.to_categorical(y_test_mnist, num_classes=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07aadb1",
   "metadata": {},
   "source": [
    "Let's first build a deep neural network to classify digits without any regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a86e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.3077 - val_accuracy: 0.9624 - val_loss: 0.1275\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.1268 - val_accuracy: 0.9719 - val_loss: 0.0880\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9711 - loss: 0.0931 - val_accuracy: 0.9735 - val_loss: 0.0796\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9769 - loss: 0.0744 - val_accuracy: 0.9749 - val_loss: 0.0767\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.0608 - val_accuracy: 0.9805 - val_loss: 0.0624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x159b85be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "        keras.layers.Dense(256,activation='relu',input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(256,activation='relu'),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10,activation='softmax') # output layer\n",
    "    ])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_mnist,y_train_mnist,\n",
    "                           epochs=5,verbose=1,batch_size=128,\n",
    "                           validation_data=(X_test_mnist,y_test_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906fee96",
   "metadata": {},
   "source": [
    "This is a feed forward fully connected neural network. That is, there is a forward pass and a backward pass but all nodes in one layer are connected to all nodes in the next layer. This mechanism is not able to capture any spatial properties in the input data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413cef0",
   "metadata": {},
   "source": [
    "Now let's train a Convolutional Neural Network. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975ccdf",
   "metadata": {},
   "source": [
    "First we will reload our input data but now in the form of images. We will keep the 28x28 shape of the inputs. Note that the 1 in 28x28x1 indicates the number of channels. Here it is one to indicate grayscale images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d4db534",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train_mnist = X_train_mnist.reshape(-1, 28,28,1).astype('float32') / 255.0\n",
    "X_test_mnist = X_test_mnist.reshape(-1, 28,28,1).astype('float32') / 255.0\n",
    "\n",
    "# Convert y labels to one-hot encoded vectors\n",
    "y_train_mnist = keras.utils.to_categorical(y_train_mnist, num_classes=10)\n",
    "y_test_mnist = keras.utils.to_categorical(y_test_mnist, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ada20c",
   "metadata": {},
   "source": [
    "There are some new layers to get familiar with. \n",
    "\n",
    "- Conv2D - convolution layer with filter size, number of filters, stride, and padding\n",
    "- max pooling layer with pool size and stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35484ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([...])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_mnist,y_train_mnist,\n",
    "                           epochs=5,verbose=1,batch_size=128,\n",
    "                           validation_data=(X_test_mnist,y_test_mnist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ddc351",
   "metadata": {},
   "source": [
    "The model summary will show that there are now stacks of filters being used in the convolution layers, which are then pooled together to further reduce, in the max pooling layers. Note that there are no additional parameters to learn from the pooling layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6d750",
   "metadata": {},
   "source": [
    "Let's modify the padding and stride values. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a0573",
   "metadata": {},
   "source": [
    "- Larger stride values reduces spatial resolution: feature map shrinks faster\n",
    "- Also speeds up training but the network might miss finer details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fae209",
   "metadata": {},
   "source": [
    "- padding = \"same\" retains spatial dimensions, helps detect objects touching the boundaries\n",
    "- Also means you can stack more layers in the network without shrinking features maps too much"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0c6df4",
   "metadata": {},
   "source": [
    "- padding = \"valid\" means no padding: reduces feature map dimensions\n",
    "- Faster but loses edge information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2605b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([...])\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train_mnist,y_train_mnist,\n",
    "                           epochs=5,verbose=1,batch_size=128,\n",
    "                           validation_data=(X_test_mnist,y_test_mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfcaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8637d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict on test data to identify correct and incorrect classifications\n",
    "y_pred_probs = model.predict(X_test_mnist)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # predicted classes\n",
    "y_true = np.argmax(y_test_mnist, axis=1)  # actual classes\n",
    "\n",
    "# separate correct and incorrect predictions\n",
    "correct_indices = np.where(y_pred == y_true)[0]\n",
    "incorrect_indices = np.where(y_pred != y_true)[0]\n",
    "\n",
    "# display up to 9 predictions in each case\n",
    "def show_images(indices, title, n=9):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i, idx in enumerate(indices[:n]):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.imshow(X_test_mnist[idx].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f\"True: {y_true[idx]}\\nPred: {y_pred[idx]}\")\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_images(correct_indices, \"Correct!\")\n",
    "show_images(incorrect_indices, \"Incorrect!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1908b4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
